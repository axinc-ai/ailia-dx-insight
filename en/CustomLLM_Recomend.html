
<!DOCTYPE HTML>
<html lang="ja" >
    <head>
        <meta charset="UTF-8">
        <title>ailia DX Insight</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="HonKit 5.1.4">
        
        
        
    
    <link rel="stylesheet" href="gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-back-to-top-button/plugin.css">
                
            
                
                <link rel="stylesheet" href="gitbook/@honkit/honkit-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
        <link rel="stylesheet" href="styles/website.css">
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="RAG.html" />
    
    
    <link rel="prev" href="CustomLLM_FastChat.html" />
    

    </head>
    <body>
        
<div class="book honkit-cloak">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="検索ワードを入力" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="./">
            
                <a href="./">
            
                    
                    <img src='img_icons/home.png'>HOME
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="overview.html">
            
                <a href="overview.html">
            
                    
                    <img src='img_icons/overview.png'>Overview
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="SetUp.html">
            
                <a href="SetUp.html">
            
                    
                    <img src='img_icons/manage_accounts.png'>Setup
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="v1_3update.html">
            
                <a href="v1_3update.html">
            
                    
                    <img src='img_icons/newspaper.png'>v1.3 release note
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="v1_2update.html">
            
                <a href="v1_2update.html">
            
                    
                    <img src='img_icons/newspaper.png'>v1.2 release note
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="v1_1update.html">
            
                <a href="v1_1update.html">
            
                    
                    <img src='img_icons/newspaper.png'>v1.0 to 1.1 Update Guide
            
                </a>
            

            
        </li>
    

    
        
        <li class="divider"></li>
        
        
    
        <li class="chapter " data-level="2.1" data-path="MainOperation.html">
            
                <a href="MainOperation.html">
            
                    
                    <img src='img_icons/label_important.png'>Main Operation Methods
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.1.1" data-path="FileView.html">
            
                <a href="FileView.html">
            
                    
                    <img src='img_icons/rule_folder.png'>Operating File View
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.1.2" data-path="IndexRegister.html">
            
                <a href="IndexRegister.html">
            
                    
                    <img src='img_icons/task.png'>Registering Files to Index
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.1.3" data-path="ConfigFile.html">
            
                <a href="ConfigFile.html">
            
                    
                    <img src='img_icons/manage_accounts.png'>Creating a Config File
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    
        
        <li class="divider"></li>
        
        
    
        <li class="chapter " data-level="3.1" data-path="UseAI.html">
            
                <a href="UseAI.html">
            
                    
                    <img src='img_icons/psychology.png'>Use AI
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.1.1" data-path="AskToAI.html">
            
                <a href="AskToAI.html">
            
                    
                    <img src='img_icons/forum.png'>Ask AI Questions
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.1.2" data-path="DocumentFile.html">
            
                <a href="DocumentFile.html">
            
                    
                    <img src='img_icons/forum.png'>Ask Questions About Document Files
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.1.3" data-path="AskAboutImage.html">
            
                <a href="AskAboutImage.html">
            
                    
                    <img src='img_icons/photo_auto_merge.png'>Ask Questions About Image Files
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.1.4" data-path="SummarizeDocument.html">
            
                <a href="SummarizeDocument.html">
            
                    
                    <img src='img_icons/summarize.png'>Summarize Document Files
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.1.5" data-path="Translation.html">
            
                <a href="Translation.html">
            
                    
                    <img src='img_icons/translate.png'>Translate Document Files
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.1.6" data-path="Proofread.html">
            
                <a href="Proofread.html">
            
                    
                    <img src='img_icons/spellcheck.png'>Proofreading document files
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.1.7" data-path="SearchImage.html">
            
                <a href="SearchImage.html">
            
                    
                    <img src='img_icons/image_search.png'>Search Images
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.1.8" data-path="GenerateImage.html">
            
                <a href="GenerateImage.html">
            
                    
                    <img src='img_icons/palette.png'>Generate Images
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.1.9" data-path="Recording.html">
            
                <a href="Recording.html">
            
                    
                    <img src='img_icons/record_voice_over.png'>Take Meeting Minutes
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.1.10" data-path="VoiceInput.html">
            
                <a href="VoiceInput.html">
            
                    
                    <img src='img_icons/mic.png'>Using Voice Input
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    
        
        <li class="divider"></li>
        
        
    
        <li class="chapter " data-level="4.1" >
            
                <span>
            
                    
                    <img src='img_icons/star.png'>Utilities
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="4.1.1" data-path="LocalLLM.html">
            
                <a href="LocalLLM.html">
            
                    
                    <img src='img_icons/tune.png'>Local LLM
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.1.2" data-path="Benchmark.html">
            
                <a href="Benchmark.html">
            
                    
                    <img src='img_icons/bar_chart.png'>Benchmark
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    
        
        <li class="divider"></li>
        
        
    
        <li class="chapter " data-level="5.1" >
            
                <span>
            
                    
                    <img src='img_icons/more.png'>More Details
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="5.1.1" data-path="Security.html">
            
                <a href="Security.html">
            
                    
                    <img src='img_icons/vpn_lock.png'>Construct Secure Environment
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="5.1.1.1" data-path="CustomLLM.html">
            
                <a href="CustomLLM.html">
            
                    
                    <img src='img_icons/tune.png'>Set up Custom LLM
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="5.1.1.2" data-path="CustomLLM_LMstudio.html">
            
                <a href="CustomLLM_LMstudio.html">
            
                    
                    <img src='img_icons/tune.png'>Build Custom LLM with LM Studio
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="5.1.1.3" data-path="CustomLLM_Ollama.html">
            
                <a href="CustomLLM_Ollama.html">
            
                    
                    <img src='img_icons/tune.png'>Build Custom LLM with Ollama
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="5.1.1.4" data-path="CustomLLM_FastChat.html">
            
                <a href="CustomLLM_FastChat.html">
            
                    
                    <img src='img_icons/tune.png'>Build Custom LLM with FastChat
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="5.1.1.5" data-path="CustomLLM_Recomend.html">
            
                <a href="CustomLLM_Recomend.html">
            
                    
                    <img src='img_icons/tune.png'>Our Recommended LLM
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="5.1.2" data-path="RAG.html">
            
                <a href="RAG.html">
            
                    
                    <img src='img_icons/book_4_spark.png'>Improve Response Accuracy with RAG
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="5.1.3" data-path="Embedding.html">
            
                <a href="Embedding.html">
            
                    
                    <img src='img_icons/polyline.png'>About Embedding
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="5.1.4" data-path="AzureOpenAI.html">
            
                <a href="AzureOpenAI.html">
            
                    
                    <img src='img_icons/psychology.png'>Azure OpenAI Service
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="5.1.5" data-path="Gemini.html">
            
                <a href="Gemini.html">
            
                    
                    <img src='img_icons/psychology.png'>Gemini
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    
        
        <li class="divider"></li>
        
        
    
        <li class="chapter " data-level="6.1" >
            
                <span>
            
                    
                    <img src='img_icons/info.png'>About OpenAI
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="6.1.1" data-path="OpenAI_APIKey.html">
            
                <a href="OpenAI_APIKey.html">
            
                    
                    <img src='img_icons/info.png'>Obtain an OpenAI API Key
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="6.1.2" data-path="Pricing.html">
            
                <a href="Pricing.html">
            
                    
                    <img src='img_icons/info.png'>OpenAI's Pricing
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="6.1.3" data-path="OpenAI_Organization.html">
            
                <a href="OpenAI_Organization.html">
            
                    
                    <img src='img_icons/info.png'>OpenAI API Organization
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    
        
        <li class="divider"></li>
        
        
    
        <li class="chapter " data-level="7.1" >
            
                <span>
            
                    
                    <img src='img_icons/play_circle.png'>External Links
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="7.1.1" >
            
                <a target="_blank" href="https://ailia.ai/en/dx/">
            
                    
                    <img src='img_icons/download.png'>Download the Evaluation App
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="7.1.2" >
            
                <a target="_blank" href="https://www.youtube.com/watch?v=2_HJTVPLWpg">
            
                    
                    <img src='img_icons/play_circle.png'>Promotion Video（YouTube）
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    
        
        <li class="divider"></li>
        
        
    
        <li class="chapter " data-level="8.1" >
            
                <a target="_blank" href="https://axinc-ai.github.io/ailia-dx-insight/">
            
                    
                    <img src='img_icons/language.png'>Language
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://github.com/honkit/honkit" target="blank" class="gitbook-link">
            HonKitで公開 
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="." ><img src='img_icons/tune.png'>Our Recommended LLM</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="recommended-llms-by-our-company">Recommended LLMs by Our Company</h1>
<p>We will introduce a list of recommended LLMs for PCs with GPU memory of less than 8GB to 8GB, classified by LLM parameter size into ultra-small, small, and medium (or larger).<br>
Some models offer multiple variants with different parameter counts, which can be identified by the numbers marked with B (Billion) within each model name. If you have extra GPU memory, you can search for and use higher models from sources like LM Studio.<br>
Please choose a model suited to your usage purpose and PC environment based on parameter size, RAM usage, and features. (The RAM usage listed may vary depending on the quantization method used).<br></p>
<p><br></p>
<h2 id="ultra-small-05b-to-4b">Ultra-Small (0.5B to 4B)</h2>
<h3 id="qwenqwen25-05b-instruct-gguf-ram-usage-118gb-or-more">Qwen/Qwen2.5-0.5B-Instruct-GGUF (RAM usage 1.18GB or more)</h3>
<h3 id="qwenqwen25-15b-instruct-gguf-ram-usage-127gb-or-more">Qwen/Qwen2.5-1.5B-Instruct-GGUF (RAM usage 1.27GB or more)</h3>
<h3 id="qwenqwen25-3b-instruct-gguf-ram-usage-144gb-or-more">Qwen/Qwen2.5-3B-Instruct-GGUF (RAM usage 1.44GB or more)</h3>
<p>Features:
These are LLMs provided by Alibaba Cloud, utilizing training data in 27 languages in addition to English and Chinese, and demonstrating high performance in benchmarks like natural language understanding, knowledge acquisition, coding, mathematics, and multilingual support.
Being an extremely small model at 0.5B, it has limited knowledge but is optimal for use on low-spec PCs.
In Qwen2.5, performance in various specialized areas has been significantly enhanced, evolving into a language model capable of handling diverse tasks.</p>
<p><br></p>
<h3 id="deepseek-r1-distill-qwen-15b-gguf-ram-usage-137gb-or-more">DeepSeek-R1-Distill-Qwen-1.5B-GGUF (RAM usage 1.37GB or more)</h3>
<p>Features:
This is a large-scale language model developed by DeepSeek in China, specialized for inference ability.
It demonstrates high performance comparable to major models in key benchmarks like inference tasks, math problems, coding, long text inference, and creative writing.
&quot;DeepSeek-R1-Distill-Qwen-14B/32B-Japanese,&quot; which has undergone additional training with Japanese data by CyberAgent, has been released.</p>
<p><br></p>
<h3 id="tinyswallow-15b-instruct-gguf-ram-usage-113gb-or-more">TinySwallow-1.5B-Instruct-GGUF (RAM usage 1.13GB or more)</h3>
<p>Features:
Announced by &quot;Sakana AI,&quot; an AI company based in Japan, this is a small-scale Japanese language model.
Developed utilizing a new knowledge distillation method called TAID (Time Adaptive Interpolation Distillation), it demonstrates the highest performance in benchmark tests evaluating Japanese functions among models of similar scale.
It is lightweight enough to operate on smartphones, enabling operation in resource-constrained environments.</p>
<p><br></p>
<h3 id="lmstudio-communitygemma-2-9b-it-gguf-ram-usage-232gb-to-915gb">lmstudio-community/gemma-2-9b-it-GGUF (RAM usage 2.32GB to 9.15GB)</h3>
<p>bartowski/gemma-2-2b-it-GGUF (RAM usage 1.79 to 3.05GB)</p>
<p>Features:
Built using the same architecture as Google’s cutting-edge AI model, Gemini, Gemma2 delivers high performance despite being lightweight.
The 27 billion parameter model, in particular, achieves top performance in its size class, rivaling models more than twice the size, while the 9 billion parameter model also shows excellent performance surpassing other open models of the same size.
Additionally, the 2 billion parameter model delivers class-leading performance relative to its size, making it suitable for use on notebooks, etc.</p>
<p><br></p>
<h3 id="microsoftphi-3-mini-4k-instruct-gguf-ram-usage-around-299gb">microsoft/Phi-3-mini-4k-instruct-gguf (RAM usage around 2.99GB)</h3>
<h3 id="quantfactoryphi-3-mini-128k-instruct-gguf-ram-usage-208-to-454gb">QuantFactory/Phi-3-mini-128k-instruct-GGUF (RAM usage 2.08 to 4.54GB)</h3>
<p>Features:
LLM provided by Microsoft, it has comparable performance to models more than twice its size despite being a very small model with 3.8B (3.8 billion parameters).
Currently, two models supporting 4K tokens and 128K tokens have been released.</p>
<p><br></p>
<h2 id="small-7b-to-9b">Small (7B to 9B)</h2>
<h3 id="qwenqwen25-7b-instruct-1m-gguf-ram-usage-197gb-or-more">Qwen/Qwen2.5-7B-Instruct-1M-GGUF (RAM usage 1.97GB or more)</h3>
<p>Features:
These are LLMs provided by Alibaba Cloud.
Utilizing training data in 27 languages in addition to English and Chinese, they demonstrate high performance in benchmarks like natural language understanding, knowledge acquisition, coding, mathematics, and multilingual support.
Qwen2.5 has evolved into a language model capable of handling diverse tasks by significantly enhancing performance in various specialized areas.
Qwen2.5-1M is developed based on Qwen2.5-Turbo, making it possible to process up to 1 million tokens of context.</p>
<p><br></p>
<h3 id="qwenqwen25-7b-instruct-gguf-ram-usage-114gb-or-more">Qwen/Qwen2.5-7B-Instruct-GGUF (RAM usage 1.14GB or more)</h3>
<p>Features:
These are LLMs provided by Alibaba Cloud.
Utilizing training data in 27 languages in addition to English and Chinese, they demonstrate high performance in benchmarks like natural language understanding, knowledge acquisition, coding, mathematics, and multilingual support.
Qwen2.5 has evolved into a language model capable of handling diverse tasks by significantly enhancing performance in various specialized areas.</p>
<p><br></p>
<h3 id="deepseek-r1-distill-qwen-7b-gguf-ram-usage-223gb-or-more">DeepSeek-R1-Distill-Qwen-7B-GGUF (RAM usage 2.23GB or more)</h3>
<h3 id="deepseek-r1-distill-llama-8b-gguf-ram-usage-204gb-or-more">DeepSeek-R1-Distill-Llama-8B-GGUF (RAM usage 2.04GB or more)</h3>
<p>Features:
A large-scale language model developed by DeepSeek in China, specialized for inference ability, demonstrating high performance comparable to major models in key benchmarks like inference tasks, math problems, coding, long text inference, and creative writing.
&quot;DeepSeek-R1-Distill-Qwen-14B/32B-Japanese,&quot; which has undergone additional training with Japanese data by CyberAgent, has been released.</p>
<p><br></p>
<h3 id="mmngaumiyuki-umievo-itr012-gleipnir-7b-gguf-ram-usage-233-to-634gb">mmnga/umiyuki-Umievo-itr012-Gleipnir-7B-gguf (RAM usage 2.33 to 6.34GB)</h3>
<p>Features:
A high-performing Japanese LLM completed by integrating four models: Japanese-Starling-ChatV-7B, Ninja-v1-RP-expressive-v2, Vecteus-v1, and Japanese-Chat-Umievo-itr004-7b4.</p>
<p><br></p>
<h3 id="mmngadatapilot-arrowpro-7b-kujira-gguf-ram-usage-226-to-349gb">mmnga/DataPilot-ArrowPro-7B-KUJIRA-gguf (RAM usage 2.26 to 3.49GB)</h3>
<h3 id="mmngaarrowpro-7b-killerwhale-gguf-ram-usage-226-to-624gb">mmnga/ArrowPro-7B-KillerWhale-gguf (RAM usage 2.26 to 6.24GB)</h3>
<p>Features:
Based on the open-source LLM &quot;NTQAI/chatntq-ja-7b-v1.0,&quot; this model was developed for use in AI applications like virtual YouTubers (AI Tubers) and AI assistants, demonstrating high performance in Japanese with high-quality conversations being highly regarded.
&quot;ArrowPro-7B-KillerWhale&quot; is positioned as an enhanced version of &quot;DataPilot/ArrowPro-7B-KUJIRA.&quot;</p>
<p><br></p>
<h3 id="mmngallama-31-8b-instruct-gguf-ram-usage-226-to-579gb">mmnga/Llama-3.1-8B-Instruct-gguf (RAM usage 2.26 to 5.79GB)</h3>
<p>Features:
The most advanced and high-performing LLM from Meta, Llama 3.1 supports advanced use cases like long-text summarization, multilingual conversation agents, coding assistance, etc., with a 128K context length, cutting-edge tool usage, and enhanced inference capabilities.</p>
<p><br></p>
<h3 id="mmngallama-3-elyza-jp-8b-gguf-ram-usage-273-to-875gb">mmnga/Llama-3-ELYZA-JP-8B-gguf (RAM usage 2.73 to 8.75GB)</h3>
<p>Features:
Designed by ELYZA, an AI company from UTokyo Matsuo Lab, this LLM is specialized for Japanese.
Based on Meta&apos;s Llama 3 8B-Instruct, it is trained using large Japanese datasets, becoming well-acquainted with Japanese grammar, vocabulary, and cultural background, enabling it to accurately understand unique Japanese expressions and nuances while generating sophisticated Japanese text.</p>
<p><br></p>
<h2 id="medium-or-larger">Medium (or Larger)</h2>
<h3 id="qwenqwen25-14b-instruct-1m-gguf">Qwen/Qwen2.5-14B-Instruct-1M-GGUF</h3>
<p>Features:
These are LLMs provided by Alibaba Cloud.
Utilizing training data in 27 languages in addition to English and Chinese, they demonstrate high performance in benchmarks like natural language understanding, knowledge acquisition, coding, mathematics, and multilingual support.
Qwen2.5 has evolved into a language model capable of handling diverse tasks by significantly enhancing performance in various specialized areas.
Qwen2.5-1M is developed based on Qwen2.5-Turbo, making it possible to process up to 1 million tokens of context.</p>
<p><br></p>
<h3 id="qwenqwen25-14b-instruct-gguf">Qwen/Qwen2.5-14B-Instruct-GGUF</h3>
<h3 id="qwenqwen25-32b-instruct-gguf">Qwen/Qwen2.5-32B-Instruct-GGUF</h3>
<h3 id="qwenqwen25-72b-instruct-gguf">Qwen/Qwen2.5-72B-Instruct-GGUF</h3>
<p>Features:
These are LLMs provided by Alibaba Cloud.
Utilizing training data in 27 languages in addition to English and Chinese, they demonstrate high performance in benchmarks like natural language understanding, knowledge acquisition, coding, mathematics, and multilingual support.
Qwen2.5 has evolved into a language model capable of handling diverse tasks by significantly enhancing performance in various specialized areas.</p>
<p><br></p>
<h3 id="deepseek-r1-distill-qwen-14b-gguf">DeepSeek-R1-Distill-Qwen-14B-GGUF</h3>
<h3 id="deepseek-r1-distill-qwen-32b-gguf">DeepSeek-R1-Distill-Qwen-32B-GGUF</h3>
<h3 id="deepseek-r1-distill-llama-70b-gguf">DeepSeek-R1-Distill-Llama-70B-GGUF</h3>
<p>Features:
These are large-scale language models developed by DeepSeek in China, specialized for inference ability.
They demonstrate high performance comparable to major models in key benchmarks like inference tasks, math problems, coding, long text inference, and creative writing.
&quot;DeepSeek-R1-Distill-Qwen-14B/32B-Japanese,&quot; which has undergone additional training with Japanese data by CyberAgent, has been released.</p>
<p><br></p>
<h3 id="mmngaelyza-japanese-llama-2-13b-fast-instruct-gguf-ram-usage-613-to-1431gb">mmnga/ELYZA-japanese-Llama-2-13b-fast-instruct-gguf (RAM usage 6.13 to 14.31GB)</h3>
<p>Features:
Designed by ELYZA, an AI company from UTokyo Matsuo Lab, this LLM is specialized for Japanese.
Based on Meta&apos;s Llama 2 13B, it is trained using large Japanese datasets, becoming well-acquainted with Japanese grammar, vocabulary, and cultural background, enabling it to accurately understand unique Japanese expressions and nuances while generating sophisticated Japanese text.</p>
<p><em>Note: A new ELYZA model based on Llama3 is expected to be released soon (as of June 27, 2024).</em></p>
<p><br></p>
<h3 id="lmstudio-communitygemma-2-27b-it-gguf-ram-usage-8-to-2965gb">lmstudio-community/gemma-2-27b-it-GGUF (RAM usage 8 to 29.65GB)</h3>
<p>Features:
Gemma2 is built using the same architecture as Google’s cutting-edge AI model, Gemini, delivering high performance despite being lightweight.
The 27 billion parameter model achieves top performance in its size class, rivaling models more than twice the size, while the 9 billion parameter model also shows excellent performance surpassing other open models of the same size.</p>
<p><br></p>
<h3 id="andrewcanisc4ai-command-r-v01-gguf-ram-usage-8-to-1027gb">andrewcanis/c4ai-command-r-v01-GGUF (RAM usage 8 to 10.27GB)</h3>
<p>Features:
Command-R is an LLM created by CohereForAI, containing 35B (35 billion) parameters.
This model excels at generating or summarizing text, or answering questions based on large amounts of information.</p>
<p><br></p>
<h2 id="supplement-about-our-recommended-llms">Supplement about our recommended LLMs</h2>
<p>When searching for recommended LLMs on LM Studio, many models are expected to appear.
We recommend using models with a 4-bit quantization that offer excellent balance between size and performance.
Specifically, models with the notation Q4_K_M or similar quantization.</p>
<p><br></p>
<h2 id="when-running-lm-studio-on-a-linux-server">When Running LM Studio on a Linux Server</h2>
<p>If you encounter the following error when trying to connect from ailia DX insight while running LM Studio on a Linux server, it might be due to the server&apos;s firewall settings prohibiting access to the port.<br>
<img src="img/CustomLLM_16.png" alt="CustomLLM_16.png"><br>
Please allow access to the port with the command<br>
 <code>sudo ufw allow 1234/tcp</code><br>
  (replace &quot;1234&quot; with the number set in LM Studio).<br>
<img src="img/CustomLLM_17.png" alt="CustomLLM_17.png"><br></p>
<p><br></p>
<h4 id="next "><a href="RAG.html">Next &gt;</a></h4>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="CustomLLM_FastChat.html" class="navigation navigation-prev " aria-label="Previous page: <img src='img_icons/tune.png'>Build Custom LLM with FastChat">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="RAG.html" class="navigation navigation-next " aria-label="Next page: <img src='img_icons/book_4_spark.png'>Improve Response Accuracy with RAG">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"<img src='img_icons/tune.png'>Our Recommended LLM","level":"5.1.1.5","depth":3,"next":{"title":"<img src='img_icons/book_4_spark.png'>Improve Response Accuracy with RAG","level":"5.1.2","depth":2,"path":"RAG.md","ref":"RAG.md","articles":[]},"previous":{"title":"<img src='img_icons/tune.png'>Build Custom LLM with FastChat","level":"5.1.1.4","depth":3,"path":"CustomLLM_FastChat.md","ref":"CustomLLM_FastChat.md","articles":[]},"dir":"ltr"},"config":{"plugins":["back-to-top-button","hide-published-with","custom-favicon"],"styles":{"website":"styles/website.css"},"pluginsConfig":{"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"hide-published-with":{},"fontsettings":{"theme":"white","family":"sans","size":2},"highlight":{},"favicon":"img/favicon.ico","back-to-top-button":{},"custom-favicon":{},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"theme":"default","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56},"embedFonts":false},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"title":"ailia DX Insight","language":"ja","gitbook":"*"},"file":{"path":"CustomLLM_Recomend.md","mtime":"2025-03-14T08:48:25.873Z","type":"markdown"},"gitbook":{"version":"5.1.4","time":"2025-05-23T10:09:28.254Z"},"basePath":".","book":{"language":""}});
        });
    </script>
</div>

        
    <noscript>
        <style>
            .honkit-cloak {
                display: block !important;
            }
        </style>
    </noscript>
    <script>
        // Restore sidebar state as critical path for prevent layout shift
        function __init__getSidebarState(defaultValue){
            var baseKey = "";
            var key = baseKey + ":sidebar";
            try {
                var value = localStorage[key];
                if (value === undefined) {
                    return defaultValue;
                }
                var parsed = JSON.parse(value);
                return parsed == null ? defaultValue : parsed;
            } catch (e) {
                return defaultValue;
            }
        }
        function __init__restoreLastSidebarState() {
            var isMobile = window.matchMedia("(max-width: 600px)").matches;
            if (isMobile) {
                // Init last state if not mobile
                return;
            }
            var sidebarState = __init__getSidebarState(true);
            var book = document.querySelector(".book");
            // Show sidebar if it enabled
            if (sidebarState && book) {
                book.classList.add("without-animation", "with-summary");
            }
        }

        try {
            __init__restoreLastSidebarState();
        } finally {
            var book = document.querySelector(".book");
            book.classList.remove("honkit-cloak");
        }
    </script>
    <script src="gitbook/gitbook.js"></script>
    <script src="gitbook/theme.js"></script>
    
        
        <script src="gitbook/gitbook-plugin-back-to-top-button/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-hide-published-with/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

